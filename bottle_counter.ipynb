{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb4256-a135-40aa-9fda-185bc51bbcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78840439-57e4-4113-a38d-28787ba398ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66874bf0-112d-44d1-90fc-2549d4b35927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov5s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c8df3-958f-4d10-8a26-acef6371717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image_path, detections, save_path=None):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for _, row in detections.iterrows():\n",
    "        box = [row['xmin'], row['ymin'], row['xmax'], row['ymax']]\n",
    "        draw.rectangle(box, outline=\"red\", width=3)\n",
    "        draw.text((box[0], box[1]), row['name'], fill=\"red\")\n",
    "    if save_path:\n",
    "        img.save(save_path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ccc977-40e8-42ca-bd88-2f9192287eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "uploader = widgets.FileUpload(accept='image/*', multiple=False)\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d29d501e-5532-499c-a541-0bf5adf0060d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\img_asgm\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\img_asgm\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\User/.cache\\torch\\hub\\master.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-8-28 Python-3.10.18 torch-2.8.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, Label, Button, Frame, ttk\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Example model paths (update with your actual paths)\n",
    "MODEL_PATHS = {\n",
    "    \"YOLOv5\": \"yolov5s.pt\",\n",
    "    \"OBR\": \"yolov5s.pt\",           # Replace with your OBR model path\n",
    "    \"Correlation\": \"yolov5s.pt\"  # Replace with your correlation model path\n",
    "}\n",
    "\n",
    "class BottleCounterApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Bottle Counter\")\n",
    "        self.root.geometry(\"540x740\")\n",
    "        self.model = None\n",
    "        self.image_path = None\n",
    "        self.result_img = None\n",
    "\n",
    "        instr = (\"Step 1: Select a model/algorithm.\\n\"\n",
    "                 \"Step 2: Click 'Upload Image' to select a photo.\\n\"\n",
    "                 \"Step 3: Click 'Count Bottles' to detect bottles.\\n\"\n",
    "                 \"Step 4: See results and bounding boxes below.\")\n",
    "        self.instr_label = Label(root, text=instr, fg=\"navy\", font=(\"Arial\", 11), justify=\"left\")\n",
    "        self.instr_label.pack(pady=10)\n",
    "\n",
    "        # Model selection\n",
    "        model_frame = Frame(root)\n",
    "        model_frame.pack(pady=5)\n",
    "        Label(model_frame, text=\"Select Model:\", font=(\"Arial\", 10)).pack(side=tk.LEFT)\n",
    "        self.model_var = tk.StringVar(value=\"YOLOv5\")\n",
    "        self.model_combo = ttk.Combobox(model_frame, textvariable=self.model_var, values=list(MODEL_PATHS.keys()), state=\"readonly\", width=15)\n",
    "        self.model_combo.pack(side=tk.LEFT, padx=10)\n",
    "        self.model_combo.bind(\"<<ComboboxSelected>>\", self.on_model_select)\n",
    "\n",
    "        # Frame for buttons\n",
    "        btn_frame = Frame(root)\n",
    "        btn_frame.pack(pady=10)\n",
    "\n",
    "        self.upload_btn = Button(btn_frame, text=\"Upload Image\", command=self.upload_image, width=15, state=tk.DISABLED)\n",
    "        self.upload_btn.grid(row=0, column=0, padx=10)\n",
    "\n",
    "        self.count_btn = Button(btn_frame, text=\"Count Bottles\", command=self.count_bottles, state=tk.DISABLED, width=15)\n",
    "        self.count_btn.grid(row=0, column=1, padx=10)\n",
    "\n",
    "        self.exit_btn = Button(btn_frame, text=\"Exit\", command=root.quit, width=10)\n",
    "        self.exit_btn.grid(row=0, column=2, padx=10)\n",
    "\n",
    "        # Status and result\n",
    "        self.status_label = Label(root, text=\"Select a model to begin.\", fg=\"blue\", font=(\"Arial\", 10))\n",
    "        self.status_label.pack(pady=5)\n",
    "\n",
    "        self.count_result = Label(root, text=\"\", fg=\"green\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.count_result.pack(pady=5)\n",
    "\n",
    "        # Canvas for image\n",
    "        self.img_label = Label(root)\n",
    "        self.img_label.pack(pady=10)\n",
    "\n",
    "        # Load default model\n",
    "        self.load_model()\n",
    "\n",
    "    def on_model_select(self, event=None):\n",
    "        self.status_label.config(text=\"Loading model, please wait...\", fg=\"blue\")\n",
    "        # Reset image and count display\n",
    "        self.img_label.config(image='')\n",
    "        self.count_result.config(text=\"\")\n",
    "        # Disable buttons until a new image is loaded and a model is loaded.\n",
    "        self.upload_btn.config(state=tk.DISABLED)\n",
    "        self.count_btn.config(state=tk.DISABLED)\n",
    "        self.load_model()\n",
    "\n",
    "    def load_model(self):\n",
    "        model_name = self.model_var.get()\n",
    "        model_path = MODEL_PATHS.get(model_name)\n",
    "        try:\n",
    "            if model_name == \"YOLOv5\":\n",
    "                # Make sure to have the yolov5 directory and its contents available\n",
    "                self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=True)\n",
    "            elif model_name == \"OBR\":\n",
    "                # Replace with your OBR model loading code\n",
    "                self.model = torch.load(model_path)\n",
    "            elif model_name == \"Correlation\":\n",
    "                # Replace with your correlation model loading code\n",
    "                self.model = torch.load(model_path)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown model selected.\")\n",
    "            self.status_label.config(text=f\"{model_name} model loaded. Ready to process images.\", fg=\"green\")\n",
    "            self.upload_btn.config(state=tk.NORMAL)\n",
    "        except Exception as e:\n",
    "            self.status_label.config(text=f\"Model load failed: {e}\", fg=\"red\")\n",
    "            self.upload_btn.config(state=tk.DISABLED)\n",
    "\n",
    "    def upload_image(self):\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select Image\",\n",
    "            filetypes=[(\"Image Files\", \"*.jpg *.jpeg *.png *.bmp\")]\n",
    "        )\n",
    "        if file_path:\n",
    "            self.image_path = file_path\n",
    "            self.display_image(file_path)\n",
    "            self.count_btn.config(state=tk.NORMAL)\n",
    "            self.count_result.config(text=\"\")\n",
    "            self.status_label.config(text=\"Image loaded. Click 'Count Bottles' to proceed.\", fg=\"blue\")\n",
    "\n",
    "    def display_image(self, img):\n",
    "        if isinstance(img, str):\n",
    "            pil_img = Image.open(img)\n",
    "        elif isinstance(img, Image.Image):\n",
    "            pil_img = img\n",
    "        else:\n",
    "            raise TypeError(\"Expected a file path (string) or a PIL Image object.\")\n",
    "\n",
    "        pil_img.thumbnail((480, 480))\n",
    "        self.tk_img = ImageTk.PhotoImage(pil_img)\n",
    "        self.img_label.config(image=self.tk_img)\n",
    "        self.img_label.image = self.tk_img\n",
    "\n",
    "    def count_bottles(self):\n",
    "        if not self.image_path:\n",
    "            messagebox.showerror(\"Error\", \"Image not loaded.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            model_name = self.model_var.get()\n",
    "            if model_name == \"YOLOv5\":\n",
    "                results = self.model(self.image_path)\n",
    "                \n",
    "                detections = results.pandas().xyxy[0]\n",
    "                bottles = detections[detections['name'] == 'bottle']\n",
    "                count = len(bottles)\n",
    "                \n",
    "                rendered_img = results.render()[0]\n",
    "                self.result_img = Image.fromarray(rendered_img)\n",
    "                \n",
    "                self.display_image(self.result_img)\n",
    "                \n",
    "            elif model_name == \"OBR\":\n",
    "                # Handle OBR detection\n",
    "                count = 0\n",
    "                original_img = Image.open(self.image_path)\n",
    "                detections = pd.DataFrame() # Placeholder\n",
    "                self.result_img = draw_boxes(original_img, detections)\n",
    "                self.display_image(self.result_img)\n",
    "                \n",
    "            elif model_name == \"Correlation\":\n",
    "                # Handle Correlation detection\n",
    "                count = 0\n",
    "                original_img = Image.open(self.image_path)\n",
    "                detections = pd.DataFrame() # Placeholder\n",
    "                self.result_img = draw_boxes(original_img, detections)\n",
    "                self.display_image(self.result_img)\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(\"Unknown model selected.\")\n",
    "                \n",
    "            self.count_result.config(text=f\"Detected {count} bottles.\")\n",
    "            self.status_label.config(text=\"Detection complete.\", fg=\"green\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to process image:\\n{e}\")\n",
    "            self.status_label.config(text=\"Error during detection.\", fg=\"red\")\n",
    "            self.count_result.config(text=\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = BottleCounterApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca03008-9ebb-41cf-b9f1-6f12b98fdd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] SIFT available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\img_asgm\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24320\\2360331169.py\", line 788, in _on_mousewheel\n",
      "    canvas.yview_scroll(int(-1*(event.delta/120)), \"units\")\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\img_asgm\\lib\\tkinter\\__init__.py\", line 1967, in yview_scroll\n",
      "    self.tk.call(self._w, 'yview', 'scroll', number, what)\n",
      "_tkinter.TclError: invalid command name \".!toplevel2.!frame.!canvas\"\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\img_asgm\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24320\\2360331169.py\", line 788, in _on_mousewheel\n",
      "    canvas.yview_scroll(int(-1*(event.delta/120)), \"units\")\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\img_asgm\\lib\\tkinter\\__init__.py\", line 1967, in yview_scroll\n",
      "    self.tk.call(self._w, 'yview', 'scroll', number, what)\n",
      "_tkinter.TclError: invalid command name \".!toplevel2.!frame.!canvas\"\n",
      "Using cache found in C:\\Users\\User/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-8-28 Python-3.10.18 torch-2.8.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\User/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "# bottle_counter_singlepane_with_vps.py\n",
    "\"\"\"\n",
    "Smart Counting Water Bottle - Single-pane Refined UI\n",
    "- Single main pane: shows original image initially, detection result after running Count\n",
    "- Models: Correlation Template Matching (CTM), Canny-Morph-Contour (CMC),\n",
    "  Watershed (Marker), Vertical Projection Segmentation (VPS), YOLOv5 (optional)\n",
    "- ROI drawing for CTM: draw rectangle, press Enter to save (rectangle disappears)\n",
    "- Step outputs shown in a resizable popup (grid of images)\n",
    "- Uses Vertical Projection Segmentation code integrated from uploaded file\n",
    "\"\"\"\n",
    "\n",
    "import sys, os, time, random, traceback\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, Label, Button, Frame, ttk, Toplevel, Canvas, Scrollbar\n",
    "\n",
    "# Optional YOLO (torch must be installed and weights path set in MODEL_PATHS)\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "except Exception:\n",
    "    TORCH_AVAILABLE = False\n",
    "\n",
    "# Put your YOLO weights path here (if you have it). The app will attempt to load if path exists.\n",
    "MODEL_PATHS = {\n",
    "    \"YOLOv5\": \"yolov5s.pt\",   # change to your weights .pt or leave as-is if you have it in working dir\n",
    "    \"Correlation Template Matching (CTM)\": None,\n",
    "    \"Canny-Morph-Contour (CMC)\": None,\n",
    "    \"Watershed (Marker)\": None,\n",
    "    \"Vertical Projection (VPS)\": None\n",
    "}\n",
    "\n",
    "# ----------------- Utility image transforms -----------------\n",
    "def _rand_id(n=6):\n",
    "    return ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=n))\n",
    "\n",
    "def laplacian_uint8(bgr):\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    lap = cv2.Laplacian(blur, cv2.CV_64F)\n",
    "    lap = np.absolute(lap)\n",
    "    maxv = lap.max() if lap.max() > 0 else 1.0\n",
    "    return np.uint8(255.0 * (lap / maxv))\n",
    "\n",
    "def sobel_mag_uint8(bgr):\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    mag = np.sqrt(gx*gx + gy*gy)\n",
    "    maxv = mag.max() if mag.max() > 0 else 1.0\n",
    "    return np.uint8(255.0 * (mag / maxv))\n",
    "\n",
    "def clahe_gray(bgr):\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(gray)\n",
    "\n",
    "def nms_indices(boxes, scores, iou_thresh=0.5):\n",
    "    if len(boxes) == 0: return []\n",
    "    boxes = np.array(boxes).astype(float)\n",
    "    scores = np.array(scores).astype(float)\n",
    "    x1 = boxes[:,0]; y1 = boxes[:,1]; x2 = boxes[:,0] + boxes[:,2]; y2 = boxes[:,1] + boxes[:,3]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = int(order[0]); keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "        w = np.maximum(0.0, xx2 - xx1); h = np.maximum(0.0, yy2 - yy1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter + 1e-8)\n",
    "        inds = np.where(ovr <= iou_thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "    return keep\n",
    "\n",
    "# ----------------- ROI selector (Enter-to-save rectangle disappears) -----------------\n",
    "class ROISelector:\n",
    "    def __init__(self, parent, pil_image, title=\"Draw ROIs (Enter to save each)\"):\n",
    "        self.parent = parent\n",
    "        self.orig_pil = pil_image.convert(\"RGB\")\n",
    "        self.orig_w, self.orig_h = self.orig_pil.size\n",
    "        self.result_rois = None\n",
    "\n",
    "        self.win = Toplevel(parent)\n",
    "        self.win.title(title)\n",
    "        self.win.transient(parent)\n",
    "        self.win.grab_set()\n",
    "        self.win.configure(bg=\"#ffffff\")\n",
    "\n",
    "        Label(self.win, text=\"Draw rectangle then press Enter to save (rectangle will disappear). Click Done when finished.\",\n",
    "              bg=\"#ffffff\", fg=\"#222\", font=(\"Segoe UI\", 10)).pack(fill=\"x\", padx=8, pady=(8,2))\n",
    "\n",
    "        # compute display size (fit to screen)\n",
    "        screen_w = self.win.winfo_screenwidth() - 200\n",
    "        screen_h = self.win.winfo_screenheight() - 200\n",
    "        max_w = min(1100, screen_w)\n",
    "        max_h = min(800, screen_h)\n",
    "        scale = min(max_w / self.orig_w, max_h / self.orig_h, 1.0)\n",
    "        self.disp_w = int(self.orig_w * scale)\n",
    "        self.disp_h = int(self.orig_h * scale)\n",
    "        self.scale_x = self.orig_w / max(1, self.disp_w)\n",
    "        self.scale_y = self.orig_h / max(1, self.disp_h)\n",
    "\n",
    "        self.disp_pil = self.orig_pil.copy()\n",
    "        self.disp_pil.thumbnail((self.disp_w, self.disp_h))\n",
    "        self.tk_img = ImageTk.PhotoImage(self.disp_pil)\n",
    "\n",
    "        self.canvas = Canvas(self.win, width=self.disp_pil.width, height=self.disp_pil.height, cursor=\"cross\", bg=\"#f6f7fb\")\n",
    "        self.canvas.pack(padx=8, pady=6)\n",
    "        self.canvas.create_image(0,0, anchor=\"nw\", image=self.tk_img)\n",
    "\n",
    "        ctrl = Frame(self.win, bg=\"#ffffff\")\n",
    "        ctrl.pack(fill=\"x\", padx=8, pady=(6,8))\n",
    "        self.count_label = Label(ctrl, text=\"Saved ROIs: 0\", bg=\"#ffffff\", font=(\"Segoe UI\", 10, \"bold\"))\n",
    "        self.count_label.pack(side=\"left\")\n",
    "        btn_frame = Frame(ctrl, bg=\"#ffffff\")\n",
    "        btn_frame.pack(side=\"right\")\n",
    "        Button(btn_frame, text=\"Done\", command=self.finish, width=10, bg=\"#4b8bbe\", fg=\"white\").pack(side=\"left\", padx=6)\n",
    "        Button(btn_frame, text=\"Clear all\", command=self.clear_all, width=10, bg=\"#e0e6ef\").pack(side=\"left\", padx=6)\n",
    "        Button(btn_frame, text=\"Cancel\", command=self.cancel, width=10, bg=\"#f2a39a\").pack(side=\"left\", padx=6)\n",
    "\n",
    "        self.pending_rect_id = None\n",
    "        self.pending_coords = None\n",
    "        self.saved_rois = []\n",
    "\n",
    "        self.canvas.bind(\"<ButtonPress-1>\", self.on_button_press)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.on_move_press)\n",
    "        self.canvas.bind(\"<ButtonRelease-1>\", self.on_button_release)\n",
    "        self.win.bind(\"<Return>\", self.on_enter_key)\n",
    "        self.win.bind(\"<Escape>\", lambda e: self.cancel())\n",
    "\n",
    "        # center window\n",
    "        self.win.update_idletasks()\n",
    "        w = self.win.winfo_width(); h = self.win.winfo_height()\n",
    "        px = int((self.win.winfo_screenwidth() - w) / 2)\n",
    "        py = int((self.win.winfo_screenheight() - h) / 2)\n",
    "        self.win.geometry(f\"+{px}+{py}\")\n",
    "        self.win.wait_window()\n",
    "\n",
    "    def on_button_press(self, event):\n",
    "        x = max(0, min(event.x, self.disp_pil.width - 1))\n",
    "        y = max(0, min(event.y, self.disp_pil.height - 1))\n",
    "        if self.pending_rect_id is not None:\n",
    "            try: self.canvas.delete(self.pending_rect_id)\n",
    "            except: pass\n",
    "            self.pending_rect_id = None\n",
    "            self.pending_coords = None\n",
    "        self.pending_rect_id = self.canvas.create_rectangle(x, y, x+1, y+1, outline=\"#ffcf3f\", width=2, dash=(4,2))\n",
    "        self.pending_coords = (x, y, x, y)\n",
    "\n",
    "    def on_move_press(self, event):\n",
    "        if self.pending_rect_id is None: return\n",
    "        cur_x = max(0, min(event.x, self.disp_pil.width - 1))\n",
    "        cur_y = max(0, min(event.y, self.disp_pil.height - 1))\n",
    "        x1, y1, _, _ = self.pending_coords\n",
    "        self.canvas.coords(self.pending_rect_id, x1, y1, cur_x, cur_y)\n",
    "        self.pending_coords = (x1, y1, cur_x, cur_y)\n",
    "\n",
    "    def on_button_release(self, event):\n",
    "        if self.pending_rect_id is None:\n",
    "            return\n",
    "        x1,y1,x2,y2 = self.canvas.coords(self.pending_rect_id)\n",
    "        x1i,y1i,x2i,y2i = int(round(min(x1,x2))), int(round(min(y1,y2))), int(round(max(x1,x2))), int(round(max(y1,y2)))\n",
    "        w = x2i - x1i; h = y2i - y1i\n",
    "        if w < 4 or h < 4:\n",
    "            try: self.canvas.delete(self.pending_rect_id)\n",
    "            except: pass\n",
    "            self.pending_rect_id = None; self.pending_coords = None\n",
    "            return\n",
    "        self.pending_coords = (x1i, y1i, x2i, y2i)\n",
    "\n",
    "    def on_enter_key(self, event=None):\n",
    "        if self.pending_rect_id is None or self.pending_coords is None:\n",
    "            return\n",
    "        x1i, y1i, x2i, y2i = self.pending_coords\n",
    "        ox = int(round(x1i * self.scale_x)); oy = int(round(y1i * self.scale_y))\n",
    "        ow = int(round((x2i - x1i) * self.scale_x)); oh = int(round((y2i - y1i) * self.scale_y))\n",
    "        ox = max(0, min(ox, self.orig_w - 1)); oy = max(0, min(oy, self.orig_h - 1))\n",
    "        if ow < 1: ow = 1\n",
    "        if oh < 1: oh = 1\n",
    "        if ox + ow > self.orig_w: ow = self.orig_w - ox\n",
    "        if oy + oh > self.orig_h: oh = self.orig_h - oy\n",
    "        self.saved_rois.append((ox, oy, ow, oh))\n",
    "        try: self.canvas.delete(self.pending_rect_id)\n",
    "        except: pass\n",
    "        self.pending_rect_id = None\n",
    "        self.pending_coords = None\n",
    "        self.count_label.config(text=f\"Saved ROIs: {len(self.saved_rois)}\")\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.saved_rois = []\n",
    "        if self.pending_rect_id is not None:\n",
    "            try: self.canvas.delete(self.pending_rect_id)\n",
    "            except: pass\n",
    "        self.pending_rect_id = None\n",
    "        self.pending_coords = None\n",
    "        self.count_label.config(text=\"Saved ROIs: 0\")\n",
    "\n",
    "    def finish(self):\n",
    "        self.result_rois = list(self.saved_rois)\n",
    "        self.win.grab_release(); self.win.destroy()\n",
    "\n",
    "    def cancel(self):\n",
    "        self.result_rois = None\n",
    "        self.win.grab_release(); self.win.destroy()\n",
    "\n",
    "# ----------------- Template Matcher (CTM) -----------------\n",
    "class TemplateMatcher:\n",
    "    def __init__(self):\n",
    "        self.sift_available = False\n",
    "        try:\n",
    "            self.sift = cv2.SIFT_create()\n",
    "            self.sift_available = True\n",
    "            print(\"[INFO] SIFT available.\")\n",
    "        except Exception:\n",
    "            self.sift = None\n",
    "            self.sift_available = False\n",
    "            print(\"[WARN] SIFT not available. Geometric verification disabled (install opencv-contrib-python).\")\n",
    "        self.w_edge = 0.5; self.w_sobel = 0.3; self.w_gray = 0.2\n",
    "\n",
    "    def gen_sub_templates(self, tpl):\n",
    "        H,W = tpl.shape[:2]\n",
    "        res = [(tpl.copy(), {'part':'full'})]\n",
    "        top_h = max(4, int(H*0.35)); res.append((tpl[0:top_h,:].copy(), {'part':'top'}))\n",
    "        mid_y = int(H*0.25); mid_h = max(4, int(H*0.5)); res.append((tpl[mid_y:mid_y+mid_h,:].copy(), {'part':'middle'}))\n",
    "        bot_h = max(4, int(H*0.35)); res.append((tpl[H-bot_h:H,:].copy(), {'part':'bottom'}))\n",
    "        return res\n",
    "\n",
    "    def geometric_verify(self, template, image_gray, ratio_test=0.75, min_inliers=6):\n",
    "        if not self.sift_available or self.sift is None:\n",
    "            return None\n",
    "        tpl_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "        detector = self.sift; matcher = cv2.BFMatcher(cv2.NORM_L2)\n",
    "        kp_t, des_t = detector.detectAndCompute(tpl_gray, None)\n",
    "        kp_i, des_i = detector.detectAndCompute(image_gray, None)\n",
    "        if des_t is None or des_i is None or len(kp_t) < 4 or len(kp_i) < 4:\n",
    "            return None\n",
    "        try:\n",
    "            raw = matcher.knnMatch(des_t, des_i, k=2)\n",
    "        except Exception:\n",
    "            return None\n",
    "        good=[]\n",
    "        for m_n in raw:\n",
    "            if len(m_n) < 2: continue\n",
    "            m,n = m_n\n",
    "            if m.distance < ratio_test * n.distance:\n",
    "                good.append(m)\n",
    "        if len(good) < 4: return None\n",
    "        pts_t = np.float32([kp_t[m.queryIdx].pt for m in good]).reshape(-1,2)\n",
    "        pts_i = np.float32([kp_i[m.trainIdx].pt for m in good]).reshape(-1,2)\n",
    "        H, mask = cv2.findHomography(pts_t, pts_i, cv2.RANSAC, 5.0)\n",
    "        if H is None or mask is None: return None\n",
    "        inliers = int(mask.sum())\n",
    "        if inliers < min_inliers: return None\n",
    "        h_t,w_t = tpl_gray.shape\n",
    "        corners = np.float32([[0,0],[w_t,0],[w_t,h_t],[0,h_t]]).reshape(-1,1,2)\n",
    "        mapped = cv2.perspectiveTransform(corners, H).reshape(-1,2)\n",
    "        x_min = int(max(0, np.min(mapped[:,0]))); y_min = int(max(0, np.min(mapped[:,1])))\n",
    "        x_max = int(min(image_gray.shape[1]-1, np.max(mapped[:,0]))); y_max = int(min(image_gray.shape[0]-1, np.max(mapped[:,1])))\n",
    "        w = max(1, x_max - x_min); h = max(1, y_max - y_min)\n",
    "        conf = min(1.0, float(inliers) / (len(good) + 1e-8))\n",
    "        return {'bbox':(x_min,y_min,w,h), 'inliers':inliers, 'conf':conf, 'method':'sift'}\n",
    "\n",
    "    def local_peaks_prominence(self, fused_map, tpl_w, tpl_h, abs_floor=0.3, max_peaks=6, prominence_factor=0.5):\n",
    "        h,w = fused_map.shape\n",
    "        k1 = max(3, int(min(tpl_w, tpl_h)/4))\n",
    "        kernel = np.ones((k1,k1), np.uint8)\n",
    "        dil = cv2.dilate(fused_map, kernel)\n",
    "        local_max_mask = fused_map >= dil\n",
    "        cand = np.argwhere(local_max_mask)\n",
    "        if cand.size == 0: return []\n",
    "        neigh = max(5, int(max(tpl_w, tpl_h)/2))\n",
    "        box = cv2.blur(fused_map.astype(np.float32), (neigh, neigh))\n",
    "        sq = cv2.blur((fused_map.astype(np.float32)**2), (neigh, neigh))\n",
    "        local_std = np.sqrt(np.maximum(0.0, sq - box*box))\n",
    "        peaks=[]\n",
    "        for (y,x) in cand:\n",
    "            score = float(fused_map[y,x])\n",
    "            lmean = float(box[y,x]); lstd = float(local_std[y,x])\n",
    "            threshold = max(abs_floor, lmean + prominence_factor * lstd)\n",
    "            if score >= threshold:\n",
    "                peaks.append((int(x), int(y), score))\n",
    "        if not peaks: return []\n",
    "        peaks.sort(key=lambda x: x[2], reverse=True)\n",
    "        min_dist = max(8, int(min(tpl_w, tpl_h)/3))\n",
    "        selected=[]\n",
    "        for (x,y,sc) in peaks:\n",
    "            too_close=False\n",
    "            for (sx,sy,ss) in selected:\n",
    "                if (x-sx)**2 + (y-sy)**2 < (min_dist**2):\n",
    "                    too_close=True; break\n",
    "            if too_close: continue\n",
    "            selected.append((x,y,sc))\n",
    "            if len(selected) >= max_peaks: break\n",
    "        return selected\n",
    "\n",
    "    def _vertical_duplicate_merge(self, detections, y_tol_ratio=0.2):\n",
    "        if not detections: return []\n",
    "        out=[]; used=[False]*len(detections)\n",
    "        for i,a in enumerate(detections):\n",
    "            if used[i]: continue\n",
    "            ax,ay,aw,ah = a['bbox']; group=[(i,a)]\n",
    "            for j,b in enumerate(detections[i+1:], start=i+1):\n",
    "                if used[j]: continue\n",
    "                bx,by,bw,bh = b['bbox']\n",
    "                center_ax = ax + aw/2; center_bx = bx + bw/2\n",
    "                dx = abs(center_ax - center_bx)\n",
    "                avg_w = (aw + bw)/2\n",
    "                yy1 = max(ay, by); yy2 = min(ay+ah, by+bh)\n",
    "                overlap_v = max(0, yy2 - yy1) / (min(ah,bh) + 1e-8)\n",
    "                if dx < avg_w*0.35 and overlap_v > y_tol_ratio:\n",
    "                    group.append((j,b)); used[j]=True\n",
    "            group.sort(key=lambda x: x[1]['score'], reverse=True)\n",
    "            out.append(group[0][1])\n",
    "        return out\n",
    "\n",
    "    def compute_simple_fused_map(self, image, tpl, weights=(0.5,0.3,0.2)):\n",
    "        edge_full = laplacian_uint8(image)\n",
    "        sobel_full = sobel_mag_uint8(image)\n",
    "        gray_full = clahe_gray(image)\n",
    "        tpl_edge = laplacian_uint8(tpl)\n",
    "        tpl_sobel = sobel_mag_uint8(tpl)\n",
    "        tpl_gray = clahe_gray(tpl)\n",
    "        th, tw = tpl_edge.shape\n",
    "        if th >= edge_full.shape[0] or tw >= edge_full.shape[1]:\n",
    "            return None, None\n",
    "        try:\n",
    "            re = cv2.matchTemplate(edge_full, tpl_edge, cv2.TM_CCOEFF_NORMED)\n",
    "        except Exception:\n",
    "            re = np.zeros((edge_full.shape[0]-th+1, edge_full.shape[1]-tw+1), dtype=np.float32)\n",
    "        try:\n",
    "            rs = cv2.matchTemplate(sobel_full, tpl_sobel, cv2.TM_CCOEFF_NORMED)\n",
    "        except Exception:\n",
    "            rs = np.zeros_like(re)\n",
    "        try:\n",
    "            rg = cv2.matchTemplate(gray_full, tpl_gray, cv2.TM_CCORR_NORMED)\n",
    "        except Exception:\n",
    "            rg = np.zeros_like(re)\n",
    "        def norm01(a):\n",
    "            a = a.astype(np.float32); amin = a.min(); amax = a.max()\n",
    "            if amax - amin < 1e-8: return np.zeros_like(a, dtype=np.float32)\n",
    "            return (a - amin) / (amax - amin + 1e-8)\n",
    "        re_n = norm01(re); rs_n = norm01(rs); rg_n = norm01(rg)\n",
    "        fused = weights[0]*re_n + weights[1]*rs_n + weights[2]*rg_n\n",
    "        fused = (fused - fused.min()) / (fused.max() - fused.min() + 1e-8)\n",
    "        fused_u8 = np.uint8(255.0 * fused)\n",
    "        heat = cv2.applyColorMap(fused_u8, cv2.COLORMAP_JET)\n",
    "        heat_up = cv2.resize(heat, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "        overlay = cv2.addWeighted(image, 0.6, heat_up, 0.4, 0)\n",
    "        pil_overlay = Image.fromarray(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "        return fused, pil_overlay\n",
    "\n",
    "# ----------------- CTM pipeline wrapper -----------------\n",
    "def model_compute_match_wrap(counter: TemplateMatcher, sub_tpl, edge_full, sobel_full, gray_full, meta, tpl_limit_params):\n",
    "    tpl_edge = laplacian_uint8(sub_tpl)\n",
    "    tpl_sobel = sobel_mag_uint8(sub_tpl)\n",
    "    tpl_gray = clahe_gray(sub_tpl)\n",
    "    th, tw = tpl_edge.shape\n",
    "    if th >= edge_full.shape[0] or tw >= edge_full.shape[1]:\n",
    "        return []\n",
    "    try:\n",
    "        re = cv2.matchTemplate(edge_full, tpl_edge, cv2.TM_CCOEFF_NORMED)\n",
    "    except Exception:\n",
    "        return []\n",
    "    try:\n",
    "        rs = cv2.matchTemplate(sobel_full, tpl_sobel, cv2.TM_CCOEFF_NORMED)\n",
    "    except Exception:\n",
    "        rs = np.zeros_like(re)\n",
    "    try:\n",
    "        rg = cv2.matchTemplate(gray_full, tpl_gray, cv2.TM_CCORR_NORMED)\n",
    "    except Exception:\n",
    "        rg = np.zeros_like(re)\n",
    "    def norm01(a):\n",
    "        a = a.astype(np.float32); amin = a.min(); amax = a.max()\n",
    "        if amax - amin < 1e-8: return np.zeros_like(a, dtype=np.float32)\n",
    "        return (a - amin) / (amax - amin + 1e-8)\n",
    "    re_n = norm01(re); rs_n = norm01(rs); rg_n = norm01(rg)\n",
    "    fused = counter.w_edge * re_n + counter.w_sobel * rs_n + counter.w_gray * rg_n\n",
    "    peaks = counter.local_peaks_prominence(fused, tw, th,\n",
    "                                          abs_floor=tpl_limit_params['min_score_absolute'],\n",
    "                                          max_peaks=tpl_limit_params['per_template_cap'],\n",
    "                                          prominence_factor=tpl_limit_params['prominence_factor'])\n",
    "    out=[]\n",
    "    for (px,py,sc) in peaks:\n",
    "        out.append({'bbox':(int(px),int(py),int(tw),int(th)), 'score':float(sc), 'meta':meta})\n",
    "    return out\n",
    "\n",
    "def run_ctm_pipeline(counter: TemplateMatcher, image, rois,\n",
    "                     do_sub_templates=True,\n",
    "                     do_augmentation=False,\n",
    "                     per_template_cap=6,\n",
    "                     min_score_absolute=0.35,\n",
    "                     prominence_factor=0.5,\n",
    "                     aspect_ratio_tolerance=0.6,\n",
    "                     nms_iou=0.5,\n",
    "                     max_workers=6):\n",
    "    t0 = time.time()\n",
    "    edge_full = laplacian_uint8(image)\n",
    "    sobel_full = sobel_mag_uint8(image)\n",
    "    gray_full = clahe_gray(image)\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    candidates = []\n",
    "    pool = ThreadPoolExecutor(max_workers=max_workers)\n",
    "    futures=[]\n",
    "    tpl_limit_params = {'per_template_cap':per_template_cap, 'min_score_absolute':min_score_absolute, 'prominence_factor':prominence_factor}\n",
    "    for tid, (x,y,w,h) in enumerate(rois, start=1):\n",
    "        tpl = image[y:y+h, x:x+w].copy()\n",
    "        subs = [(tpl.copy(), {'part':'full'})]\n",
    "        if do_sub_templates:\n",
    "            subs = counter.gen_sub_templates(tpl)\n",
    "        for sub_tpl, meta in subs:\n",
    "            meta2 = {'template_id':tid, 'scale':1.0, 'rot':0, 'bright':1.0, 'part':meta['part']}\n",
    "            futures.append(pool.submit(lambda st=sub_tpl, m=meta2: model_compute_match_wrap(counter, st, edge_full, sobel_full, gray_full, m, tpl_limit_params)))\n",
    "    for f in as_completed(futures):\n",
    "        try:\n",
    "            out = f.result()\n",
    "            for c in out:\n",
    "                candidates.append(c)\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] worker failed:\", e)\n",
    "    pool.shutdown(wait=True)\n",
    "\n",
    "    # geometric verification (SIFT-only)\n",
    "    geom_added=[]\n",
    "    if counter.sift_available:\n",
    "        by_tid={}\n",
    "        for c in candidates:\n",
    "            tid = c.get('meta',{}).get('template_id', None)\n",
    "            if tid is None: continue\n",
    "            by_tid.setdefault(tid, []).append(c)\n",
    "        for tid, lst in by_tid.items():\n",
    "            lst.sort(key=lambda x: x['score'], reverse=True)\n",
    "            cap = min(len(lst), 6)\n",
    "            orig_tpl = image[rois[tid-1][1]:rois[tid-1][1]+rois[tid-1][3], rois[tid-1][0]:rois[tid-1][0]+rois[tid-1][2]].copy()\n",
    "            for c in lst[:cap]:\n",
    "                gm = counter.geometric_verify(orig_tpl, cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), ratio_test=0.75, min_inliers=6)\n",
    "                if gm is not None:\n",
    "                    geom_added.append({'bbox':gm['bbox'], 'score':gm['conf'], 'method':gm['method'], 'template_id':tid, 'meta':{'inliers':gm['inliers']}})\n",
    "\n",
    "    final_candidates = candidates.copy()\n",
    "    for g in geom_added: final_candidates.append(g)\n",
    "\n",
    "    filtered=[]\n",
    "    for c in final_candidates:\n",
    "        bx,by,bw,bh = c['bbox']; sc = c['score']\n",
    "        if sc < min_score_absolute: continue\n",
    "        tid = c.get('meta',{}).get('template_id', None)\n",
    "        if tid is not None:\n",
    "            rx,ry,rw,rh = rois[tid-1]\n",
    "            tpl_ar = rw / (rh + 1e-8)\n",
    "            cand_ar = bw / (bh + 1e-8)\n",
    "            ar_ratio = cand_ar / (tpl_ar + 1e-8)\n",
    "            if ar_ratio < aspect_ratio_tolerance or ar_ratio > (1.0 / aspect_ratio_tolerance):\n",
    "                continue\n",
    "        filtered.append(c)\n",
    "\n",
    "    if len(filtered) == 0:\n",
    "        return [], 0, None\n",
    "\n",
    "    boxes = [c['bbox'] for c in filtered]; scores = [c['score'] for c in filtered]\n",
    "    keep = nms_indices(boxes, scores, iou_thresh=nms_iou)\n",
    "    final = [filtered[i] for i in keep]\n",
    "    final.sort(key=lambda x: x['score'], reverse=True)\n",
    "    final = counter._vertical_duplicate_merge(final, y_tol_ratio=0.25)\n",
    "    t1 = time.time()\n",
    "    print(f\"[INFO] CTM final detections: {len(final)}. Time: {t1-t0:.2f}s\")\n",
    "    return final, len(final), None\n",
    "\n",
    "# ----------------- CMC (Canny + Morphology + Contour) -----------------\n",
    "def classical_detect_and_draw_steps(image_path, min_area=1000, low_thresh=50, high_thresh=150, kernel_size=(5,5)):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None: raise ValueError(\"Could not open image.\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, low_thresh, high_thresh)\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    closing = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    result = img.copy(); bottle_count = 0; detections=[]\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > min_area:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(result, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "            bottle_count += 1\n",
    "            detections.append({'xmin':x,'ymin':y,'xmax':x+w,'ymax':y+h,'name':'bottle','area':area})\n",
    "    # do not overlay large text inside image (we'll display count label above separately)\n",
    "    pil_result = Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    pil_original = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    pil_edges = Image.fromarray(edges); pil_closing = Image.fromarray(closing)\n",
    "    import pandas as pd\n",
    "    detections_df = pd.DataFrame(detections)\n",
    "    return bottle_count, pil_result, detections_df, pil_original, pil_edges, pil_closing\n",
    "\n",
    "# ----------------- Watershed (improved preprocessing) -----------------\n",
    "def watershed_detect_and_draw_steps(image_path, area_threshold=1000, dist_thresh_factor=0.25):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Could not open image.\")\n",
    "    orig = img.copy()\n",
    "    # Improved preprocessing steps to try to increase Watershed accuracy:\n",
    "    # - CLAHE for contrast\n",
    "    # - bilateral filter to reduce noise while preserving edges\n",
    "    # - morphological opening to remove small objects, then closing\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    blur = cv2.bilateralFilter(gray, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    # Use adaptive threshold or Otsu. Start with OTSU but fallback to adaptive if necessary.\n",
    "    try:\n",
    "        _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    except Exception:\n",
    "        thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    # opening removes small noise; closing fills small holes\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    sure_bg = cv2.dilate(closing, kernel, iterations=3)\n",
    "    dist_transform = cv2.distanceTransform(closing, cv2.DIST_L2, 5)\n",
    "    # distance threshold can be tuned (lower -> more seeds -> possibly oversegment)\n",
    "    _, sure_fg = cv2.threshold(dist_transform, dist_thresh_factor * dist_transform.max(), 255, 0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    num_labels, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 1\n",
    "    markers[unknown == 255] = 0\n",
    "    markers = cv2.watershed(orig, markers)\n",
    "    result = orig.copy()\n",
    "    result[markers == -1] = [0,0,255]\n",
    "    bottle_count = 0\n",
    "    detections = []\n",
    "    for label in np.unique(markers):\n",
    "        if label <= 1:\n",
    "            continue\n",
    "        mask = np.uint8(markers == label)\n",
    "        area = cv2.countNonZero(mask)\n",
    "        if area > area_threshold:\n",
    "            bottle_count += 1\n",
    "            cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cv2.drawContours(result, cnts, -1, (0,255,0), 2)\n",
    "            for cnt in cnts:\n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                detections.append({'xmin':x,'ymin':y,'xmax':x+w,'ymax':y+h,'name':'bottle','area':area})\n",
    "    pil_result = Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    pil_original = Image.fromarray(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB))\n",
    "    pil_thresh = Image.fromarray(thresh)\n",
    "    pil_closing = Image.fromarray(closing)\n",
    "    pil_sure_bg = Image.fromarray(sure_bg)\n",
    "    pil_sure_fg = Image.fromarray(sure_fg)\n",
    "    import pandas as pd\n",
    "    detections_df = pd.DataFrame(detections)\n",
    "    return bottle_count, pil_result, detections_df, pil_original, pil_thresh, pil_closing, pil_sure_bg, pil_sure_fg\n",
    "\n",
    "# ----------------- Vertical Projection Segmentation (integrated) -----------------\n",
    "# (Adapted from your uploaded Vertical Projection Segmentation.txt)\n",
    "PROC_TARGET_HEIGHT = 800\n",
    "EDGE_MAG_THRESH = 50\n",
    "COL_SMOOTH_WIN  = 9\n",
    "COL_MIN_VAL     = 10\n",
    "GAP_MERGE_PX    = 10\n",
    "SLICE_MIN_W     = 60\n",
    "SLICE_MIN_H     = 120\n",
    "\n",
    "def resize_for_processing(bgr, target_h=PROC_TARGET_HEIGHT):\n",
    "    H, W = bgr.shape[:2]\n",
    "    if H == 0 or W == 0:\n",
    "        raise ValueError(\"Invalid image dimensions\")\n",
    "    scale = target_h / float(H)\n",
    "    new_w = max(1, int(round(W * scale)))\n",
    "    interp = cv2.INTER_AREA if scale < 1.0 else cv2.INTER_CUBIC\n",
    "    resized = cv2.resize(bgr, (new_w, target_h), interpolation=interp)\n",
    "    return resized, (1.0/scale)\n",
    "\n",
    "def preprocess_for_edges(bgr):\n",
    "    g = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    g = clahe.apply(g)\n",
    "    blur = cv2.GaussianBlur(g, (0,0), 2.0)\n",
    "    sharp = cv2.addWeighted(g, 1.8, blur, -0.8, 0)\n",
    "    gx = cv2.Sobel(sharp, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    mag = cv2.convertScaleAbs(np.abs(gx))\n",
    "    return mag\n",
    "\n",
    "def column_projection(mag, thresh=EDGE_MAG_THRESH, smooth_win=COL_SMOOTH_WIN):\n",
    "    m = mag.copy()\n",
    "    m[m < thresh] = 0\n",
    "    col = m.sum(axis=0).astype(np.float32)\n",
    "    k = max(3, int(smooth_win)|1)\n",
    "    kernel = np.ones(k, np.float32)/k\n",
    "    col_smooth = np.convolve(col, kernel, mode='same')\n",
    "    return col_smooth\n",
    "\n",
    "def segments_from_projection(col_smooth, min_val=COL_MIN_VAL, gap_merge=GAP_MERGE_PX):\n",
    "    W = len(col_smooth)\n",
    "    mask = (col_smooth >= min_val).astype(np.uint8)\n",
    "    segs, in_run, start = [], False, 0\n",
    "    for x in range(W):\n",
    "        if mask[x] and not in_run:\n",
    "            in_run, start = True, x\n",
    "        elif not mask[x] and in_run:\n",
    "            in_run = False; segs.append([start, x-1])\n",
    "    if in_run: segs.append([start, W-1])\n",
    "    if not segs: return []\n",
    "    merged=[segs[0]]\n",
    "    for s,e in segs[1:]:\n",
    "        ps,pe = merged[-1]\n",
    "        if s - pe - 1 <= gap_merge:\n",
    "            merged[-1][1] = e\n",
    "        else:\n",
    "            merged.append([s,e])\n",
    "    return merged\n",
    "\n",
    "def refine_box_from_area(mag, x1, x2, pix_thresh=EDGE_MAG_THRESH):\n",
    "    slice_mag = mag[:, x1:x2+1]\n",
    "    m = (slice_mag >= pix_thresh).astype(np.uint8)\n",
    "    Hs, Ws = m.shape\n",
    "    min_rows = max(3, int(0.02 * Hs))\n",
    "    min_cols = max(3, int(0.02 * Ws))\n",
    "    col_counts = m.sum(axis=0)\n",
    "    row_counts = m.sum(axis=1)\n",
    "    good_cols = np.where(col_counts >= min_rows)[0]\n",
    "    good_rows = np.where(row_counts >= min_cols)[0]\n",
    "    if good_cols.size >= 2 and good_rows.size >= 2:\n",
    "        x_min, x_max = good_cols.min(), good_cols.max()\n",
    "        y_min, y_max = good_rows.min(), good_rows.max()\n",
    "    else:\n",
    "        ys, xs = np.where(m)\n",
    "        if ys.size == 0:\n",
    "            return x1, 0, x2, mag.shape[0]-1\n",
    "        x_min, x_max = xs.min(), xs.max()\n",
    "        y_min, y_max = ys.min(), ys.max()\n",
    "    X1 = x1 + int(x_min)\n",
    "    X2 = x1 + int(x_max)\n",
    "    Y1 = int(y_min)\n",
    "    Y2 = int(y_max)\n",
    "    return X1, Y1, X2, Y2\n",
    "\n",
    "def nms(boxes, iou_thr=0.3):\n",
    "    if not boxes: return []\n",
    "    b = np.array(boxes, dtype=np.float32)\n",
    "    x1,y1,x2,y2 = b[:,0],b[:,1],b[:,2],b[:,3]\n",
    "    areas = (x2-x1+1)*(y2-y1+1)\n",
    "    order = areas.argsort()[::-1]\n",
    "    keep=[]\n",
    "    while order.size>0:\n",
    "        i=order[0]; keep.append(i)\n",
    "        xx1=np.maximum(x1[i],x1[order[1:]])\n",
    "        yy1=np.maximum(y1[i],y1[order[1:]])\n",
    "        xx2=np.minimum(x2[i],x2[order[1:]])\n",
    "        yy2=np.minimum(y2[i],y2[order[1:]])\n",
    "        w=np.maximum(0.0, xx2-xx1+1)\n",
    "        h=np.maximum(0.0, yy2-yy1+1)\n",
    "        inter=w*h\n",
    "        iou=inter/(areas[i]+areas[order[1:]]-inter+1e-6)\n",
    "        inds=np.where(iou<=iou_thr)[0]\n",
    "        order=order[inds+1]\n",
    "    return [boxes[i] for i in keep]\n",
    "\n",
    "def boxes_from_vertical_projection(bgr, return_debug=False):\n",
    "    resized, back_scale = resize_for_processing(bgr, PROC_TARGET_HEIGHT)\n",
    "    mag = preprocess_for_edges(resized)\n",
    "    col_s = column_projection(mag)\n",
    "    segs = segments_from_projection(col_s)\n",
    "    boxes_norm=[]\n",
    "    for (x1, x2) in segs:\n",
    "        if x2 - x1 + 1 < SLICE_MIN_W:\n",
    "            continue\n",
    "        X1t, Y1t, X2t, Y2t = refine_box_from_area(mag, x1, x2)\n",
    "        if (X2t - X1t + 1) < SLICE_MIN_W or (Y2t - Y1t + 1) < SLICE_MIN_H:\n",
    "            continue\n",
    "        boxes_norm.append([X1t, Y1t, X2t, Y2t])\n",
    "    if boxes_norm:\n",
    "        boxes_norm = nms(boxes_norm, iou_thr=0.3)\n",
    "    s = back_scale\n",
    "    boxes_orig = [[int(round(x1*s)), int(round(y1*s)),\n",
    "                   int(round(x2*s)), int(round(y2*s))] for (x1,y1,x2,y2) in boxes_norm]\n",
    "    if not return_debug:\n",
    "        return boxes_orig\n",
    "    debug = {\n",
    "        \"resized_bgr\": resized,\n",
    "        \"mag\": mag,\n",
    "        \"segments\": segs,\n",
    "        \"boxes_norm\": boxes_norm\n",
    "    }\n",
    "    return boxes_orig, debug\n",
    "\n",
    "def build_segmentation_panel(debug):\n",
    "    resized = debug[\"resized_bgr\"].copy()\n",
    "    H, W = resized.shape[:2]\n",
    "    mag   = debug[\"mag\"]\n",
    "    segs  = debug[\"segments\"]\n",
    "    boxes = debug[\"boxes_norm\"]\n",
    "    mag_norm = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    mag_rgb  = cv2.cvtColor(mag_norm, cv2.COLOR_GRAY2BGR)\n",
    "    seg_vis = resized.copy()\n",
    "    overlay = seg_vis.copy()\n",
    "    for (x1, x2) in segs:\n",
    "        cv2.rectangle(overlay, (x1, 0), (x2, H-1), (0, 255, 255), -1)\n",
    "    seg_vis = cv2.addWeighted(overlay, 0.25, seg_vis, 0.75, 0)\n",
    "    for (x1,y1,x2,y2) in boxes:\n",
    "        cv2.rectangle(seg_vis, (x1,y1), (x2,y2), (0,0,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(mag_rgb, \"Edge magnitude\", (6, 16),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1, cv2.LINE_AA)\n",
    "    cv2.putText(seg_vis, \"Segmentation view\", (6, 16),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50,50,50), 2, cv2.LINE_AA)\n",
    "    # concat horizontally; if sizes mismatch, pad\n",
    "    try:\n",
    "        return cv2.hconcat([mag_rgb, seg_vis])\n",
    "    except Exception:\n",
    "        return seg_vis\n",
    "\n",
    "def draw_boxes(bgr, boxes, color=(0,0,255), thick=2):\n",
    "    vis = bgr.copy()\n",
    "    for (x1,y1,x2,y2) in boxes:\n",
    "        cv2.rectangle(vis, (int(x1),int(y1)), (int(x2),int(y2)), color, thick, cv2.LINE_AA)\n",
    "    # no large overlay text here (we display count above)\n",
    "    return vis\n",
    "\n",
    "# ----------------- Step popup (resizable & grid, no big empty margins) -----------------\n",
    "def show_steps_popup_images(parent, images_with_titles, title=\"Step Outputs\"):\n",
    "    popup = Toplevel(parent)\n",
    "    popup.title(title)\n",
    "    popup.transient(parent)\n",
    "    popup.resizable(True, True)\n",
    "    screen_w = popup.winfo_screenwidth()\n",
    "    screen_h = popup.winfo_screenheight()\n",
    "    init_w = int(min(screen_w * 0.85, 1400))\n",
    "    init_h = int(min(screen_h * 0.85, 900))\n",
    "    popup.geometry(f\"{init_w}x{init_h}\")\n",
    "    outer = Frame(popup)\n",
    "    outer.pack(fill=\"both\", expand=True)\n",
    "    canvas = Canvas(outer)\n",
    "    v_scroll = Scrollbar(outer, orient=\"vertical\", command=canvas.yview)\n",
    "    h_scroll = Scrollbar(outer, orient=\"horizontal\", command=canvas.xview)\n",
    "    canvas.configure(yscrollcommand=v_scroll.set, xscrollcommand=h_scroll.set)\n",
    "    v_scroll.pack(side=\"right\", fill=\"y\")\n",
    "    h_scroll.pack(side=\"bottom\", fill=\"x\")\n",
    "    canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "    inner = Frame(canvas)\n",
    "    canvas.create_window((0,0), window=inner, anchor=\"nw\")\n",
    "    n = len(images_with_titles)\n",
    "    if n <= 2:\n",
    "        cols = n if n>0 else 1\n",
    "    elif n <= 4:\n",
    "        cols = 2\n",
    "    else:\n",
    "        cols = 3\n",
    "    padding = 12\n",
    "    # choose thumbnail size to fill width neatly (avoid large empty areas)\n",
    "    thumb_w = max(160, int((init_w - (cols+1)*padding) / cols))\n",
    "    thumb_h = int(thumb_w * 0.7)\n",
    "    inner._photo_refs = []\n",
    "    for idx, (title, pil_img) in enumerate(images_with_titles):\n",
    "        r = idx // cols; c = idx % cols\n",
    "        frame = Frame(inner, bd=0, relief=\"flat\", padx=6, pady=6)\n",
    "        frame.grid(row=r, column=c, padx=8, pady=8, sticky=\"nsew\")\n",
    "        Label(frame, text=title, font=(\"Segoe UI\", 10, \"bold\")).pack(anchor=\"w\")\n",
    "        img_copy = pil_img.copy()\n",
    "        img_copy.thumbnail((thumb_w, thumb_h))\n",
    "        tk_img = ImageTk.PhotoImage(img_copy)\n",
    "        inner._photo_refs.append(tk_img)\n",
    "        lbl = Label(frame, image=tk_img)\n",
    "        lbl.pack(padx=2, pady=6)\n",
    "    for col in range(cols):\n",
    "        inner.grid_columnconfigure(col, weight=1)\n",
    "    btn_frame = Frame(popup)\n",
    "    btn_frame.pack(fill=\"x\", padx=8, pady=6)\n",
    "    Button(btn_frame, text=\"Close\", command=lambda: (popup.grab_release(), popup.destroy()), width=12, bg=\"#4b8bbe\", fg=\"white\").pack(side=\"right\", padx=6)\n",
    "    def _on_configure(event=None):\n",
    "        popup.update_idletasks()\n",
    "        bbox = canvas.bbox(\"all\")\n",
    "        if bbox is None:\n",
    "            bbox = (0,0,init_w,init_h)\n",
    "        canvas.configure(scrollregion=bbox)\n",
    "    inner.bind(\"<Configure>\", lambda e: _on_configure())\n",
    "    popup.bind(\"<Configure>\", lambda e: _on_configure())\n",
    "    def _on_mousewheel(event):\n",
    "        if event.state & 0x0001:\n",
    "            canvas.xview_scroll(int(-1*(event.delta/120)), \"units\")\n",
    "        else:\n",
    "            canvas.yview_scroll(int(-1*(event.delta/120)), \"units\")\n",
    "    canvas.bind_all(\"<MouseWheel>\", _on_mousewheel)\n",
    "    canvas.bind_all(\"<Button-4>\", lambda e: canvas.yview_scroll(-1, \"units\"))\n",
    "    canvas.bind_all(\"<Button-5>\", lambda e: canvas.yview_scroll(1, \"units\"))\n",
    "    popup.update_idletasks()\n",
    "    popup.grab_set()\n",
    "    popup.wait_window()\n",
    "\n",
    "# ----------------- Draw boxes helper for Pandas DataFrame -----------------\n",
    "def draw_boxes_pil(pil_img, detections_df, box_color=(0,255,0), thickness=2):\n",
    "    import numpy as _np\n",
    "    img_cv = cv2.cvtColor(_np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "    for _, row in detections_df.iterrows():\n",
    "        x1,y1,x2,y2 = int(row.get('xmin',0)), int(row.get('ymin',0)), int(row.get('xmax',0)), int(row.get('ymax',0))\n",
    "        cv2.rectangle(img_cv, (x1,y1),(x2,y2), box_color, thickness)\n",
    "        label = str(row.get('name',''))\n",
    "        if label:\n",
    "            cv2.putText(img_cv, label, (x1, max(y1-6,0)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 1, cv2.LINE_AA)\n",
    "    return Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# ----------------- Main GUI: Single-pane refined -----------------\n",
    "class BottleCounterApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Smart Counting Water Bottle\")\n",
    "        self.root.geometry(\"980x760\")\n",
    "        self.root.configure(bg=\"#f6f8fb\")\n",
    "        self.root.protocol(\"WM_DELETE_WINDOW\", self.on_exit)\n",
    "\n",
    "        self.template_matcher = None\n",
    "        self.image_path = None\n",
    "        self.orig_bgr = None         # original BGR (kept)\n",
    "        self.current_display_pil = None  # PIL image currently displayed (original or result)\n",
    "        self.result_pil = None\n",
    "        self.yolo_model = None\n",
    "        self._last_rois = None\n",
    "\n",
    "        self.canvas_img_id = None\n",
    "        self.display_scale = 1.0\n",
    "\n",
    "        self._build_ui()\n",
    "\n",
    "    def _build_ui(self):\n",
    "        header = Frame(self.root, bg=\"#ffffff\", bd=0)\n",
    "        header.pack(fill=\"x\", padx=12, pady=(10,6))\n",
    "        title = Label(header, text=\"Smart Counting Water Bottle\", font=(\"Segoe UI\", 18, \"bold\"), bg=\"#ffffff\", fg=\"#1f4e79\")\n",
    "        title.pack(anchor=\"w\", padx=10, pady=(6,0))\n",
    "        subtitle = Label(header, text=\"Choose algorithm → Upload image → Count\", font=(\"Segoe UI\", 10), bg=\"#ffffff\", fg=\"#5a6b7a\")\n",
    "        subtitle.pack(anchor=\"w\", padx=10, pady=(0,8))\n",
    "\n",
    "        ctrl_card = Frame(self.root, bg=\"#ffffff\", bd=1, relief=\"groove\")\n",
    "        ctrl_card.pack(fill=\"x\", padx=12, pady=(0,10))\n",
    "        ctrl = Frame(ctrl_card, bg=\"#ffffff\", pady=8)\n",
    "        ctrl.pack(fill=\"x\", padx=8)\n",
    "\n",
    "        Label(ctrl, text=\"Model:\", font=(\"Segoe UI\", 10), bg=\"#ffffff\").pack(side=\"left\", padx=(6,8))\n",
    "        self.model_var = tk.StringVar(value=\"Correlation Template Matching (CTM)\")\n",
    "        model_list = [\"Correlation Template Matching (CTM)\", \"Canny-Morph-Contour (CMC)\", \"Watershed (Marker)\", \"Vertical Projection (VPS)\", \"YOLOv5\"]\n",
    "        self.model_combo = ttk.Combobox(ctrl, textvariable=self.model_var, values=model_list, state=\"readonly\", width=36)\n",
    "        self.model_combo.pack(side=\"left\", padx=(0,8))\n",
    "        self.model_combo.bind(\"<<ComboboxSelected>>\", self.on_model_select)\n",
    "\n",
    "        self.upload_btn = Button(ctrl, text=\"Upload Image\", width=14, command=self.upload_image, bg=\"#2b7bd3\", fg=\"white\")\n",
    "        self.upload_btn.pack(side=\"left\", padx=6)\n",
    "\n",
    "        self.count_btn = Button(ctrl, text=\"Count Bottles\", width=14, command=self.count_bottles, bg=\"#2baf6a\", fg=\"white\", state=\"disabled\")\n",
    "        self.count_btn.pack(side=\"left\", padx=6)\n",
    "\n",
    "        self.exit_btn = Button(ctrl, text=\"Exit\", width=10, command=self.on_exit, bg=\"#e06666\", fg=\"white\")\n",
    "        self.exit_btn.pack(side=\"right\", padx=10)\n",
    "\n",
    "        # result card: single panel showing original first then result\n",
    "        card = Frame(self.root, bg=\"#ffffff\", bd=1, relief=\"solid\")\n",
    "        card.pack(fill=\"both\", expand=True, padx=12, pady=(0,12))\n",
    "        topbar = Frame(card, bg=\"#ffffff\")\n",
    "        topbar.pack(fill=\"x\")\n",
    "        Label(topbar, text=\"Detection Result\", bg=\"#ffffff\", font=(\"Segoe UI\", 11, \"bold\")).pack(side=\"left\", padx=8, pady=8)\n",
    "\n",
    "        # status area above image: left small status + right big Total text\n",
    "        status_area = Frame(card, bg=\"#ffffff\")\n",
    "        status_area.pack(fill=\"x\", padx=8)\n",
    "        self.processing_label = Label(status_area, text=\"\", bg=\"#ffffff\", fg=\"#666\", font=(\"Segoe UI\", 10))\n",
    "        self.processing_label.pack(side=\"left\", padx=(2,6), pady=6)\n",
    "        self.total_label = Label(status_area, text=\"\", bg=\"#ffffff\", fg=\"#2b7bd3\", font=(\"Segoe UI\", 14, \"bold\"))\n",
    "        self.total_label.pack(side=\"right\", padx=8, pady=6)\n",
    "\n",
    "        # single canvas with scrollbars\n",
    "        canvas_outer = Frame(card, bg=\"#ffffff\")\n",
    "        canvas_outer.pack(fill=\"both\", expand=True, padx=8, pady=(4,8))\n",
    "        self.canvas = Canvas(canvas_outer, bg=\"#f6f7fb\")\n",
    "        self.vscroll = Scrollbar(canvas_outer, orient=\"vertical\", command=self.canvas.yview)\n",
    "        self.hscroll = Scrollbar(canvas_outer, orient=\"horizontal\", command=self.canvas.xview)\n",
    "        self.canvas.configure(yscrollcommand=self.vscroll.set, xscrollcommand=self.hscroll.set)\n",
    "        self.canvas.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        self.vscroll.grid(row=0, column=1, sticky=\"ns\")\n",
    "        self.hscroll.grid(row=1, column=0, sticky=\"we\")\n",
    "        canvas_outer.rowconfigure(0, weight=1); canvas_outer.columnconfigure(0, weight=1)\n",
    "        # mouse wheel to scroll; Ctrl+wheel to zoom\n",
    "        self.canvas.bind(\"<MouseWheel>\", self._on_canvas_mousewheel)\n",
    "        self.canvas.bind(\"<Button-4>\", lambda e: self._on_canvas_mousewheel_linux(e, -1))\n",
    "        self.canvas.bind(\"<Button-5>\", lambda e: self._on_canvas_mousewheel_linux(e, 1))\n",
    "\n",
    "        # status footer\n",
    "        status = Frame(self.root, bg=\"#ffffff\")\n",
    "        status.pack(fill=\"x\", padx=12, pady=(0,10))\n",
    "        self.status_var = tk.StringVar(value=\"Ready\")\n",
    "        Label(status, textvariable=self.status_var, anchor=\"w\", bg=\"#ffffff\", fg=\"#333\").pack(side=\"left\", padx=8, pady=6)\n",
    "\n",
    "        self.on_model_select()\n",
    "\n",
    "    # ----------------- canvas zoom & scroll -----------------\n",
    "    def _on_canvas_mousewheel(self, event):\n",
    "        if event.state & 0x0004:  # Ctrl pressed => zoom\n",
    "            if event.delta == 0: return\n",
    "            factor = 1.0 + (event.delta/1200.0)\n",
    "            self.display_scale = max(0.05, min(6.0, self.display_scale * factor))\n",
    "            self._render_display_image()\n",
    "        else:\n",
    "            if event.delta == 0: return\n",
    "            self.canvas.yview_scroll(int(-1*(event.delta/120)), \"units\")\n",
    "\n",
    "    def _on_canvas_mousewheel_linux(self, event, direction):\n",
    "        if (event.state & 0x0004):\n",
    "            factor = 1.0 + (-direction * 0.08)\n",
    "            self.display_scale = max(0.05, min(6.0, self.display_scale * factor))\n",
    "            self._render_display_image()\n",
    "        else:\n",
    "            self.canvas.yview_scroll(direction, \"units\")\n",
    "\n",
    "    # ----------------- render display (fit to canvas without empty margins) -----------------\n",
    "    def _render_display_image(self):\n",
    "        # if no image, clear\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.canvas_img_id = None\n",
    "        pil = self.current_display_pil\n",
    "        if pil is None:\n",
    "            self.canvas.config(scrollregion=(0,0,0,0))\n",
    "            return\n",
    "        # compute available inner size for canvas\n",
    "        canvas_w = max(200, self.canvas.winfo_width() or 600)\n",
    "        canvas_h = max(200, self.canvas.winfo_height() or 400)\n",
    "        # scale image to fit canvas tightly while keeping aspect ratio and avoid empty margins:\n",
    "        img_w, img_h = pil.width, pil.height\n",
    "        # Use display_scale as multiplier on the \"fit\" scale so user can zoom out/in around a fitted size\n",
    "        fit_scale = min(canvas_w / img_w, canvas_h / img_h)\n",
    "        final_scale = max(0.01, fit_scale * self.display_scale)\n",
    "        new_w = int(img_w * final_scale); new_h = int(img_h * final_scale)\n",
    "        if new_w < 1 or new_h < 1:\n",
    "            return\n",
    "        resized = pil.resize((new_w, new_h), Image.LANCZOS)\n",
    "        self.tk_display_img = ImageTk.PhotoImage(resized)\n",
    "        self.canvas_img_id = self.canvas.create_image(0,0, anchor=\"nw\", image=self.tk_display_img)\n",
    "        # set scrollregion to exactly image size — no empty margins shown\n",
    "        self.canvas.config(scrollregion=(0,0,new_w, new_h))\n",
    "        # keep reference to avoid garbage collection\n",
    "        self.canvas._img_ref = self.tk_display_img\n",
    "\n",
    "    # ----------------- UI actions -----------------\n",
    "    def on_model_select(self, event=None):\n",
    "        model_name = self.model_var.get()\n",
    "        self.status_var.set(\"Model: \" + model_name)\n",
    "        if model_name == \"Correlation Template Matching (CTM)\":\n",
    "            try:\n",
    "                self.template_matcher = TemplateMatcher()\n",
    "                if self.template_matcher.sift_available:\n",
    "                    self.status_var.set(\"CTM selected — SIFT available\")\n",
    "                else:\n",
    "                    self.status_var.set(\"CTM selected — SIFT not available\")\n",
    "            except Exception:\n",
    "                self.template_matcher = None\n",
    "                self.status_var.set(\"CTM init failed\")\n",
    "        elif model_name == \"YOLOv5\":\n",
    "            if not TORCH_AVAILABLE:\n",
    "                self.yolo_model = None\n",
    "                self.status_var.set(\"YOLOv5 selected — torch not available\")\n",
    "                messagebox.showwarning(\"YOLO\", \"torch not available in this environment. YOLO disabled.\")\n",
    "            else:\n",
    "                model_path = MODEL_PATHS.get(\"YOLOv5\")\n",
    "                if model_path is None or not Path(model_path).exists():\n",
    "                    self.yolo_model = None\n",
    "                    self.status_var.set(\"YOLOv5 selected — weights not found\")\n",
    "                else:\n",
    "                    try:\n",
    "                        self.status_var.set(\"Loading YOLO model...\")\n",
    "                        self.root.update_idletasks()\n",
    "                        self.yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=False)\n",
    "                        self.status_var.set(\"YOLOv5 loaded.\")\n",
    "                    except Exception as e:\n",
    "                        self.yolo_model = None\n",
    "                        self.status_var.set(\"YOLO load failed\")\n",
    "                        messagebox.showerror(\"YOLO load failed\", str(e))\n",
    "        else:\n",
    "            self.template_matcher = None\n",
    "            self.status_var.set(model_name + \" selected\")\n",
    "        # when switching algorithm, restore original image if present\n",
    "        if self.orig_bgr is not None:\n",
    "            self.current_display_pil = Image.fromarray(cv2.cvtColor(self.orig_bgr, cv2.COLOR_BGR2RGB))\n",
    "            self.display_scale = 1.0\n",
    "            self._render_display_image()\n",
    "        self.count_btn.config(state=\"normal\" if self.orig_bgr is not None else \"disabled\")\n",
    "\n",
    "    def upload_image(self):\n",
    "        file_path = filedialog.askopenfilename(title=\"Select image\", filetypes=[(\"Image Files\",\"*.jpg *.jpeg *.png *.bmp *.tiff\")])\n",
    "        if not file_path:\n",
    "            return\n",
    "        bgr = cv2.imread(file_path)\n",
    "        if bgr is None:\n",
    "            messagebox.showerror(\"Error\", \"Cannot read image file.\")\n",
    "            return\n",
    "        self.image_path = file_path\n",
    "        self.orig_bgr = bgr\n",
    "        self.result_pil = None\n",
    "        self._last_rois = None\n",
    "        self.current_display_pil = Image.fromarray(cv2.cvtColor(self.orig_bgr, cv2.COLOR_BGR2RGB))\n",
    "        self.display_scale = 1.0\n",
    "        self._render_display_image()\n",
    "        self.count_btn.config(state=\"normal\")\n",
    "        self.status_var.set(\"Image loaded. Choose model and press Count Bottles.\")\n",
    "        self.total_label.config(text=\"\")\n",
    "        self.processing_label.config(text=\"\")\n",
    "\n",
    "    def count_bottles(self):\n",
    "        if self.orig_bgr is None:\n",
    "            messagebox.showerror(\"No image\", \"Please upload an image first.\")\n",
    "            return\n",
    "        model_name = self.model_var.get()\n",
    "        self.status_var.set(\"Processing...\"); self.processing_label.config(text=\"Processing...\")\n",
    "        self.root.update_idletasks()\n",
    "        try:\n",
    "            if model_name == \"Canny-Morph-Contour (CMC)\":\n",
    "                count, pil_result, detections_df, pil_original, pil_edges, pil_closing = classical_detect_and_draw_steps(self.image_path)\n",
    "                # Steps popup\n",
    "                images = [(\"Original\", pil_original), (\"Edges (Canny)\", pil_edges.convert(\"RGB\")),\n",
    "                          (\"After Morphology\", pil_closing.convert(\"RGB\")), (\"Detection\", pil_result)]\n",
    "                show_steps_popup_images(self.root, images, title=\"CMC Steps\")\n",
    "                # show result in main pane\n",
    "                self.result_pil = pil_result\n",
    "                self.current_display_pil = self.result_pil\n",
    "                self.display_scale = 1.0\n",
    "                self._render_display_image()\n",
    "                self.total_label.config(text=f\"Total Bottles: {count}\")\n",
    "                self.processing_label.config(text=\"Done\")\n",
    "                self.status_var.set(\"CMC completed.\")\n",
    "\n",
    "            elif model_name == \"Watershed (Marker)\":\n",
    "                # improved watershed (preprocessing included)\n",
    "                count, pil_result, detections_df, pil_original, pil_thresh, pil_closing, pil_sure_bg, pil_sure_fg = watershed_detect_and_draw_steps(self.image_path, area_threshold=1000, dist_thresh_factor=0.25)\n",
    "                images = [(\"Original\", pil_original),\n",
    "                          (\"Threshold (Binary)\", pil_thresh.convert(\"RGB\") if pil_thresh.mode != \"RGB\" else pil_thresh),\n",
    "                          (\"After Closing\", pil_closing.convert(\"RGB\") if pil_closing.mode != \"RGB\" else pil_closing),\n",
    "                          (\"Sure Background\", pil_sure_bg.convert(\"RGB\") if pil_sure_bg.mode != \"RGB\" else pil_sure_bg),\n",
    "                          (\"Sure Foreground\", pil_sure_fg.convert(\"RGB\") if pil_sure_fg.mode != \"RGB\" else pil_sure_fg),\n",
    "                          (\"Final detection\", pil_result)]\n",
    "                show_steps_popup_images(self.root, images, title=\"Watershed Steps\")\n",
    "                self.result_pil = pil_result\n",
    "                self.current_display_pil = self.result_pil\n",
    "                self.display_scale = 1.0\n",
    "                self._render_display_image()\n",
    "                self.total_label.config(text=f\"Total Bottles: {count}\")\n",
    "                self.processing_label.config(text=\"Done\")\n",
    "                self.status_var.set(\"Watershed completed.\")\n",
    "\n",
    "            elif model_name == \"Vertical Projection (VPS)\":\n",
    "                # run vertical projection segmentation\n",
    "                boxes, debug = boxes_from_vertical_projection(self.orig_bgr, return_debug=True)\n",
    "                vis = draw_boxes(self.orig_bgr, boxes, color=(0,255,0))\n",
    "                pil_vis = Image.fromarray(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "                seg_panel_cv = build_segmentation_panel(debug)\n",
    "                pil_seg_panel = Image.fromarray(cv2.cvtColor(seg_panel_cv, cv2.COLOR_BGR2RGB))\n",
    "                images = [(\"Original\", Image.fromarray(cv2.cvtColor(self.orig_bgr, cv2.COLOR_BGR2RGB))),\n",
    "                          (\"Edge magnitude & Segmentation\", pil_seg_panel),\n",
    "                          (\"Detection\", pil_vis)]\n",
    "                show_steps_popup_images(self.root, images, title=\"VPS Steps\")\n",
    "                self.result_pil = pil_vis\n",
    "                self.current_display_pil = self.result_pil\n",
    "                self.display_scale = 1.0\n",
    "                self._render_display_image()\n",
    "                self.total_label.config(text=f\"Total Bottles: {len(boxes)}\")\n",
    "                self.processing_label.config(text=\"Done\")\n",
    "                self.status_var.set(\"VPS completed.\")\n",
    "\n",
    "            elif model_name == \"Correlation Template Matching (CTM)\":\n",
    "                rois = getattr(self, \"_last_rois\", None)\n",
    "                # ask for ROI if not provided\n",
    "                if rois is None:\n",
    "                    pil_orig = Image.fromarray(cv2.cvtColor(self.orig_bgr, cv2.COLOR_BGR2RGB))\n",
    "                    selector = ROISelector(self.root, pil_orig)\n",
    "                    rois = selector.result_rois\n",
    "                    if rois is None:\n",
    "                        self.status_var.set(\"ROI selection cancelled.\")\n",
    "                        self.processing_label.config(text=\"Cancelled\")\n",
    "                        return\n",
    "                    if not rois:\n",
    "                        messagebox.showinfo(\"No ROI\", \"No ROI selected; aborting.\")\n",
    "                        self.status_var.set(\"No ROI selected.\")\n",
    "                        self.processing_label.config(text=\"Cancelled\")\n",
    "                        return\n",
    "                if self.template_matcher is None:\n",
    "                    self.template_matcher = TemplateMatcher()\n",
    "                final, count, _ = run_ctm_pipeline(self.template_matcher, self.orig_bgr, rois,\n",
    "                                                   do_sub_templates=True, do_augmentation=False,\n",
    "                                                   per_template_cap=6, min_score_absolute=0.35,\n",
    "                                                   prominence_factor=0.5, aspect_ratio_tolerance=0.6,\n",
    "                                                   nms_iou=0.5, max_workers=6)\n",
    "                out_cv = self.orig_bgr.copy()\n",
    "                for i,m in enumerate(final, start=1):\n",
    "                    x,y,w,h = m['bbox']; sc = m.get('score',0.0); tid = m.get('template_id', -1)\n",
    "                    cv2.rectangle(out_cv, (x,y),(x+w,y+h), (0,255,0), 2)\n",
    "                    cv2.putText(out_cv, f\"{i}:T{tid}:{sc:.2f}\", (x, max(12,y-6)), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,255,0), 1)\n",
    "                pil_final = Image.fromarray(cv2.cvtColor(out_cv, cv2.COLOR_BGR2RGB))\n",
    "                # show steps: include ROI overlay, edges, fused overlay if available\n",
    "                orig_with_rois = self.orig_bgr.copy()\n",
    "                for idx,(xx,yy,ww,hh) in enumerate(rois, start=1):\n",
    "                    cv2.rectangle(orig_with_rois, (xx,yy),(xx+ww,yy+hh),(0,255,0),2)\n",
    "                    cv2.putText(orig_with_rois, f\"ROI{idx}\", (xx, max(12,yy-6)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "                pil_orig_rois = Image.fromarray(cv2.cvtColor(orig_with_rois, cv2.COLOR_BGR2RGB))\n",
    "                pil_edge = Image.fromarray(laplacian_uint8(self.orig_bgr))\n",
    "                pil_sobel = Image.fromarray(sobel_mag_uint8(self.orig_bgr))\n",
    "                pil_clahe = Image.fromarray(clahe_gray(self.orig_bgr))\n",
    "                fused_overlay = None\n",
    "                try:\n",
    "                    tpl_roi = self.orig_bgr[rois[0][1]:rois[0][1]+rois[0][3], rois[0][0]:rois[0][0]+rois[0][2]].copy()\n",
    "                    fused_map, fused_overlay = self.template_matcher.compute_simple_fused_map(self.orig_bgr, tpl_roi, weights=(self.template_matcher.w_edge, self.template_matcher.w_sobel, self.template_matcher.w_gray))\n",
    "                except Exception:\n",
    "                    fused_overlay = pil_edge.convert(\"RGB\")\n",
    "                images = [(\"Original + ROIs\", pil_orig_rois),\n",
    "                          (\"Laplacian (edge)\", pil_edge.convert(\"RGB\")),\n",
    "                          (\"Sobel magnitude\", pil_sobel.convert(\"RGB\")),\n",
    "                          (\"CLAHE gray\", pil_clahe.convert(\"RGB\")),\n",
    "                          (\"Fused score overlay (ROI1)\", fused_overlay),\n",
    "                          (\"Final detection\", pil_final)]\n",
    "                show_steps_popup_images(self.root, images, title=\"CTM Steps\")\n",
    "                self.result_pil = pil_final\n",
    "                self.current_display_pil = self.result_pil\n",
    "                self.display_scale = 1.0\n",
    "                self._render_display_image()\n",
    "                self.total_label.config(text=f\"Total Bottles: {count}\")\n",
    "                self.processing_label.config(text=\"Done\")\n",
    "                # clear rois if you want (we keep not to force reselect)\n",
    "                self._last_rois = None\n",
    "                self.status_var.set(\"CTM completed.\")\n",
    "\n",
    "            elif model_name == \"YOLOv5\":\n",
    "                if not TORCH_AVAILABLE or self.yolo_model is None:\n",
    "                    # attempt to load if path ok\n",
    "                    model_path = MODEL_PATHS.get(\"YOLOv5\")\n",
    "                    if TORCH_AVAILABLE and model_path and Path(model_path).exists():\n",
    "                        try:\n",
    "                            self.status_var.set(\"Loading YOLO model...\")\n",
    "                            self.root.update_idletasks()\n",
    "                            self.yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=False)\n",
    "                        except Exception as e:\n",
    "                            self.yolo_model = None\n",
    "                            self.status_var.set(\"YOLO load failed\")\n",
    "                            messagebox.showerror(\"YOLO load failed\", str(e))\n",
    "                            return\n",
    "                    else:\n",
    "                        messagebox.showerror(\"YOLO Error\", \"YOLOv5 model not loaded. Check torch and weights configuration.\")\n",
    "                        self.status_var.set(\"YOLO not available.\")\n",
    "                        return\n",
    "                results = self.yolo_model(self.image_path)\n",
    "                detections = results.pandas().xyxy[0]\n",
    "                # attempt robust filtering for 'bottle'\n",
    "                if 'name' in detections.columns:\n",
    "                    bottles = detections[detections['name'].str.lower() == 'bottle']\n",
    "                else:\n",
    "                    bottles = detections\n",
    "                count = len(bottles)\n",
    "                rendered = results.render()\n",
    "                if len(rendered) > 0:\n",
    "                    arr = rendered[0]\n",
    "                    try:\n",
    "                        pil_result = Image.fromarray(arr)\n",
    "                    except Exception:\n",
    "                        pil_result = Image.fromarray(cv2.cvtColor(arr, cv2.COLOR_BGR2RGB))\n",
    "                    self.result_pil = pil_result\n",
    "                    self.current_display_pil = self.result_pil\n",
    "                    self._render_display_image()\n",
    "                else:\n",
    "                    # fallback: draw boxes and show\n",
    "                    self.result_pil = draw_boxes_pil(Image.open(self.image_path).convert(\"RGB\"), bottles)\n",
    "                    self.current_display_pil = self.result_pil\n",
    "                    self._render_display_image()\n",
    "                self.total_label.config(text=f\"Total Bottles: {count}\")\n",
    "                self.processing_label.config(text=\"Done\")\n",
    "                self.status_var.set(\"YOLO completed.\")\n",
    "\n",
    "            else:\n",
    "                self.status_var.set(\"Unknown model selected.\")\n",
    "                self.processing_label.config(text=\"\")\n",
    "\n",
    "            messagebox.showinfo(\"Done\", \"Detection finished. Result shown in the main pane.\")\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            messagebox.showerror(\"Error\", f\"Processing failed:\\n{e}\")\n",
    "            self.status_var.set(\"Error during detection.\")\n",
    "            self.processing_label.config(text=\"Error\")\n",
    "        finally:\n",
    "            try:\n",
    "                self.root.update_idletasks(); self.root.update()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def on_exit(self):\n",
    "        try: cv2.destroyAllWindows()\n",
    "        except: pass\n",
    "        try:\n",
    "            self.root.quit(); self.root.destroy()\n",
    "        except:\n",
    "            try: sys.exit(0)\n",
    "            except: pass\n",
    "\n",
    "# ----------------- run -----------------\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = BottleCounterApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06ae38-762d-46df-ad8f-c74c0b54c3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a24cb-3ef4-428c-9c5f-a8842d735ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:img_asgm]",
   "language": "python",
   "name": "conda-env-img_asgm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
